[{"entryType":"COMMENT","entry":"com,memo={ThistextfileisencodedinUTF-8.}"},{"entryType":"COMMENT","entry":"com2,memo={Internationalpublicationsfollows.}"},{"citationKey":"chi2024-kato-griffith","entryType":"inproceedings","entryTags":{"title":"Griffith: A Storyboarding Tool Designed with Japanese Animation Professionals","author":"Kato, Jun and Hara, Kenta and Hirasawa, Nao","year":"2024","booktitle":"Proceedings of the CHI Conference on Human Factors in Computing Systems","location":"Honolulu, HI, USA","publisher":"ACM","address":"New York, NY, USA","series":"CHI '24","doi":"10.1145/3613904.3642121","isbn":"9798400703300","url":"https://doi.org/10.1145/3613904.3642121","abstract":"The \"E-conte,\" storyboard in English, is commonly referred to as the \"blueprint\" in Japanese animation (anime) production, consisting of scene illustrations, timing information, and textual descriptions. This paper introduces ``Griffith,'' a digital system for creating these storyboards. Due to its highly cultural and domain-specific nature, the tool design entailed an in-depth study of the E-conte process and a longitudinal collaboration with an experienced anime director and producers. The resulting system contributes not only domain knowledge, but also generalizable insights into a creativity support environment for visual storytelling, including the importance of vertical timelines and discrete yet integrated tools. To reflect on the interaction design, we presented Griffith to professionals with diverse roles in anime production. Our findings highlight the benefits of the Griffith user interface and the need for a socio-technical focus in designing creativity support tools.","articleno":"233","numpages":"14","keywords":"creativity support, animation, storyboard, user interface","project":"griffith"}},{"citationKey":"ieice2024-tsuchida-danceunisoner","entryType":"article","entryTags":{"title":"DanceUnisoner: A Parametric,  Visual,  and Interactive Simulation Interface for Choreographic Composition of Group Dance","author":"Tsuchida, Shuhei and Fukayama, Satoru and Kato, Jun and Yakura, Hiromu and Goto, Masataka","year":"2024","month":"mar","journal":"IEICE Transactions on Information and Systems","publisher":"Institute of Electronics,  Information and Communications Engineers (IEICE)","volume":"E107.D","number":"3","pages":"386--399","doi":"10.1587/transinf.2023edp7063","issn":"1745-1361","url":"http://dx.doi.org/10.1587/transinf.2023EDP7063"}},{"citationKey":"xrds2023summer-kato-toolsmith","entryType":"article","entryTags":{"title":"On the Relationship between HCI Researchers and Creators---Or How I Became a Toolsmith","author":"Kato, Jun","year":"2023","month":"jun","journal":"XRDS","publisher":"Association for Computing Machinery","address":"New York, NY, USA","volume":"29","number":"4","pages":"26--31","doi":"10.1145/3596927","issn":"1528-4972","url":"https://doi.org/10.1145/3596927","issue_date":"Summer 2023","abstract":"Research on creativity support tools in human-computer interaction often focuses on novel interaction design, but that is just the tip of the iceberg. Let's dive deeper and help creative activities \"in the wild.\"","numpages":"6","project":"creativity-support-environments","addition":"Invited article"}},{"citationKey":"sas2023-kato-lights-animation-interaction","entryType":"unpublished","entryTags":{"title":"Lights, Animation, Interaction! – Synchronizing Music with Computer-controlled Visuals in Live Performances","author":"Jun Kato","year":"2023","month":"jun","booktitle":"Society for Animation Studies 34th Annual Conference: The Animated Environment","series":"SAS 34","abstract":"The author is a computer scientist with expertise in Human-Computer Interaction research who has developed a digital tool, \"TextAlive\" (https://junkato.jp/textalive), that allows the creation of lyric videos. The lyric video is a timed art in which lyric text animates in synchrony with the musical piece and is often used in modern live music performances, displayed on large and bright displays on the stage. While assisting in the production of such lyric videos, he noticed an unexpected preference for simple kinetic typography. It turned out that complex animations could be overwhelming for the audience to prevent them from concentrating on the singer, who was supposed to be the show's star. This paper discusses the past, present, and future of the role of lighting animations in live music performances. The past is examined from a historical perspective based on a literature survey; the present is revealed from a practitioner's perspective based on the author's own experience and interviews with creators; the future is discussed from a computer scientist's perspective and case studies, including musical performances in virtual reality (VR). Conventional stage lighting devices such as spotlights can be regarded as huge and bright pixels driven and animated by strong motors. While they have the advantage in luminous intensity, they have physical limitations in movement speed and patterns, resulting in simple use cases such as flashing to musical beats and guiding the audience's gaze to focus on the singer. A modern and precise display technology that synchronously emits light from many pixels has enabled more diverse artistic expressions, such as showing lyric videos and other relevant content as the stage background. The animating pixels can also be seen on the audience seats, including their smartphones and lighting bracelets, controlled by wireless signals and other synchronization techniques. With the recent advances in virtual reality (VR) technologies and under the COVID-19 impact, live music performances in VR spaces are also becoming common, where even the singer becomes part of the animating lighting pixels. These diverse lighting animations form the animated environment, a rich information environment that envelops the singer and audience. Technology development has increased the amount of information produced and controlled in performing arts, which has already reached saturation concerning the audience's capacity to process information. For animation artists, it will be more of a matter of finding effective ways of combining different kinds of lighting animations and adjusting the coarseness and density of the information over time.","slides":"https://junkato.jp/publications/sas34-kato-lights-animation-interaction.pdf","project":"textalive"}},{"citationKey":"chi2023-kato-lyric-app-framework","entryType":"inproceedings","entryTags":{"title":"Lyric App Framework: A Web-based Framework for Developing Interactive Lyric-driven Musical Applications","author":"Kato, Jun and Goto, Masataka","year":"2023","booktitle":"Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","location":"Hamburg, Germany","publisher":"ACM","address":"New York, NY, USA","series":"CHI '23","doi":"10.1145/3544548.3580931","isbn":"9781450394215","url":"https://doi.org/10.1145/3544548.3580931","abstract":"Lyric videos have become a popular medium to convey lyrical content to listeners, but they present the same content whenever they are played and cannot adapt to listeners’ preferences. Lyric apps, as we name them, are a new form of lyric-driven visual art that can render different lyrical content depending on user interaction and address the limitations of static media. To open up this novel design space for programmers and musicians, we present Lyric App Framework, a web-based framework for building interactive graphical applications that play musical pieces and show lyrics synchronized with playback. We designed the framework to provide a streamlined development experience for building production-ready lyric apps with creative coding libraries of choice. We held programming contests twice and collected 52 examples of lyric apps, enabling us to reveal eight representative categories, confirm the framework’s effectiveness, and report lessons learned.","articleno":"124","numpages":"18","keywords":"toolkit, multimedia control, music synchronization","slides":"https://junkato.jp/publications/chi2023-kato-lyric-apps-slides.pdf","project":"lyric-app-framework","addition":"ACM CHI '23 Honorable Mention Award"}},{"citationKey":"chi2023-kato-sigccc","entryType":"inproceedings","entryTags":{"title":"Special Interest Group on Creativity and Cultures in Computing","author":"Kato, Jun and Frich, Jonas and Lu, Zhicong and Jacobs, Jennifer and Nakakoji, Kumiyo and Latulipe, Celine","year":"2023","booktitle":"Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems","location":"Hamburg, Germany","publisher":"ACM","address":"New York, NY, USA","series":"CHI EA '23","doi":"10.1145/3544549.3583175","isbn":"9781450394222","url":"https://doi.org/10.1145/3544549.3583175","abstract":"Research on creativity support tools (CSTs) has a long history in Human-Computer Interaction (HCI); however, researchers often focus on developing novel CSTs and verifying them in a controlled lab setting, rather than on capturing the creative process in the wild. In reality, creative activity is exploratory, laborious, and involves multiple CSTs; which together form a creativity support environment or ecology. Creative activity is also social, cultural, and collaborative with people distributing, modifying, and reacting to the creations of others. This process can inspire subsequent iterations. To understand and support open-ended, culturally embedded, collaborative creativity, HCI researchers are seeking new methods to study the sociocultural aspects of creativity support. This Special Interest Group on Creativity and Cultures in Computing (SIGCCC) invites diverse researchers to provide a forum for CST discussions from a wide sociocultural lens. The participants will identify and discuss the state-of-the-art and conceptualize future directions for creativity support research.","articleno":"520","numpages":"4","keywords":"interaction design, psychology, creativity support, social science","slides":"https://docs.google.com/presentation/d/1rEJHF0xtPZvGeC3wIiBYlGBujbpMktelXFvD2OvR04I/edit","project":"creativity-support-environments"}},{"citationKey":"sas2022-kato-toolsmiths-in-anime","entryType":"unpublished","entryTags":{"title":"Past, Present, and Future of “Toolsmiths” in Japanese Animation","author":"Jun Kato","year":"2022","month":"jun","booktitle":"Society for Animation Studies 2022 Conference: Animation Unlocked","series":"SAS '22","slides":"https://research.archinc.jp/static/files/sas2022-kato-toolsmiths-in-anime.pdf","project":"griffith","affiliation":"Arch Inc."}},{"citationKey":"isid2022-kato-toolsmiths-in-anime","entryType":"inproceedings","entryTags":{"title":"Griffith: Prototype of A Web-based Tool for Authoring Japanese Anime Storyboards","author":"Kato, Jun and Murata, Kazuya and Hara, Kenta and Okuno, Satoko and Suzuki, Tetsushi and Hirasawa, Nao","year":"2022","location":"Online","series":"ISID '22","url":"https://research.archinc.jp/static/files/isid2022-kato-griffith-prototype.pdf","addition":"ISID '22 Best Poster Award","project":"griffith","affiliation":"Arch Inc."}},{"citationKey":"iui2022-zhao-oden","entryType":"inproceedings","entryTags":{"title":"ODEN: Live Programming for Neural Network Architecture Editing","author":"Zhao, Chunqi and Shen, I-Chao and Fukusato, Tsukasa and Kato, Jun and Igarashi, Takeo","year":"2022","booktitle":"27th International Conference on Intelligent User Interfaces","location":"Helsinki, Finland","publisher":"Association for Computing Machinery","address":"New York, NY, USA","series":"IUI '22","pages":"392--404","doi":"10.1145/3490099.3511120","isbn":"9781450391443","url":"https://doi.org/10.1145/3490099.3511120","abstract":"In deep learning application development, programmers tend to try different architectures and hyper-parameters until satisfied with the model performance. Nevertheless, program crashes due to tensor shape mismatch prohibit programmers, especially novice programmers, from smoothly going back and forth between neural network&nbsp;(NN) architecture editing and experimentation. We propose to leverage live programming techniques in NN architecture editing with an always-on visualization. When the user edits the program, the visualization can synchronously display tensor states and provide a warning message by continuously executing the program to prevent program crashes during experimentation. We implement the live visualization and integrate it into an IDE called ODEN that seamlessly supports the “edit→experiment→edit→···” repetition. With ODEN, the user can construct the neural network with the live visualization and transits into experimentation to instantly train and test the NN architecture. An exploratory user study is conducted to evaluate the usability, the limitations, and the potential of live visualization in ODEN.","numpages":"13","keywords":"neural networks, programming experience, deep learning programming"}},{"citationKey":"vlhcc2021-ikarashi-rolypoly","entryType":"inproceedings","entryTags":{"title":"Guided Optimization for Image Processing Pipelines","author":"Yuka Ikarashi and Jonathan Ragan-Kelley and Tsukasa Fukusato and Jun Kato and Takeo Igarashi","year":"2021","month":"oct","booktitle":"Proceedings of the 2021 IEEE Symposium on Visual Languages and Human-Centric Computing","publisher":"IEEE Computer Society","address":"Los Alamitos, CA, USA","series":"VL/HCC '21","doi":"10.1109/VL/HCC51201.2021.9576341","url":"https://doi.ieeecomputersociety.org/10.1109/VL/HCC51201.2021.9576341","keywords":"visualization;schedules;codes;costs;processor scheduling;image processing;estimation","numpages":"4","pdf":"https://arxiv.org/abs/2107.12567","addition":"IEEE VL/HCC '21 Best Short Paper Award"}},{"citationKey":"sas2021-kato-storyboarding-in-anime","entryType":"unpublished","entryTags":{"title":"Past, Present, and Future of Storyboarding in Japanese Animation","author":"Jun Kato and Ryotaro Mihara and Nao Hirasawa","year":"2021","month":"jun","booktitle":"Society for Animation Studies 2021 Conference: Animated Energies","series":"SAS '21","note":"Session: Anime","slides":"https://research.archinc.jp/static/files/sas2021-kato-storyboarding-in-anime.pdf","project":"griffith","affiliation":"Arch Inc."}},{"citationKey":"isid2021-kato-anime-storyboards","entryType":"inproceedings","entryTags":{"title":"Research on Anime Storyboards for Individual and Collaborative Creativity","author":"Kato, Jun and Mihara, Ryotaro Mihara and Murata, Kazuya and Hara, Kenta and Hirasawa, Nao","year":"2021","location":"Online","series":"ISID '21","url":"https://research.archinc.jp/static/files/isid2021-kato-anime-storyboards.pdf","addition":"ISID '21 Best Poster Award","project":"griffith","affiliation":"Arch Inc."}},{"citationKey":"das2020-sakaguchi-lyric-video-analysis","entryType":"inproceedings","entryTags":{"title":"Lyric Video Analysis Using Text Detection and Tracking","author":"Shota Sakaguchi and Jun Kato and Masataka Goto and Seiichi Uchida","year":"2020","booktitle":"Document Analysis Systems","publisher":"Springer International Publishing","address":"Cham","series":"DAS '20","pages":"426--440","doi":"10.1007/978-3-030-57058-3_30","isbn":"978-3-030-57058-3","url":"https://doi.org/10.1007/978-3-030-57058-3_30","editor":"Xiang Bai and Dimosthenis Karatzas and Daniel Lopresti","numpages":"15","pdf":"https://arxiv.org/pdf/2006.11933.pdf","abstract":"We attempt to recognize and track lyric words in lyric videos. Lyric video is a music video showing the lyric words of a song. The main characteristic of lyric videos is that the lyric words are shown at frames synchronously with the music. The difficulty of recognizing and tracking the lyric words is that (1) the words are often decorated and geometrically distorted and (2) the words move arbitrarily and drastically in the video frame. The purpose of this paper is to analyze the motion of the lyric words in lyric videos, as the first step of automatic lyric video generation. In order to analyze the motion of lyric words, we first apply a state-of-the-art scene text detector and recognizer to each video frame. Then, lyric-frame matching is performed to establish the optimal correspondence between lyric words and the frames. After fixing the motion trajectories of individual lyric words from correspondence, we analyze the trajectories of the lyric words by k-medoids clustering and dynamic time warping (DTW)."}},{"citationKey":"ccs2020-kato-rethink-prog-env","entryType":"inproceedings","entryTags":{"title":"Rethinking Programming \"Environment\": Technical and Social Environment Design toward Convivial Computing","author":"Jun Kato and Keisuke Shimakage","year":"2020","booktitle":"Companion Proceedings of the 4th International Conference on the Art, Science, and Engineering of Programming","location":"Porto, Portugal","publisher":"ACM","address":"New York, NY, USA","series":"Convivial Computing Salon '20","pages":"95--103","doi":"10.1145/3397537.3397544","url":"https://doi.org/10.1145/3397537.3397544","numpages":"9","keywords":"Convivial computing, programming environments, programming experience, live programming, social coding","project":"programming-as-communication","pdf":"https://junkato.jp/publications/ccs2020-kato-rethink-prog-env.pdf","slides":"https://junkato.jp/publications/ccs2020-kato-rethink-prog-env-slides.pdf"}},{"citationKey":"plateau2019-zhao-live-programming-for-deep","entryType":"inproceedings","entryTags":{"title":"Live Programming Environment for Deep Learning with Instant and Editable Neural Network Visualization","author":"Chunqi Zhao and Tsukasa Fukusato and Jun Kato and Takeo Igarashi","year":"2020","booktitle":"10th Workshop on Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019)","publisher":"Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik","address":"Dagstuhl, Germany","series":"PLATEAU '19","volume":"76","pages":"7:1--7:5","doi":"10.4230/OASIcs.PLATEAU.2019.7","isbn":"978-3-95977-135-1","issn":"2190-6807","url":"https://drops.dagstuhl.de/opus/volltexte/2020/11961","editor":"Sarah Chasins and Elena L. Glassman and Joshua Sunshine","urn":"urn:nbn:de:0030-drops-119613","annote":"Keywords: Neural network visualization, Live programming, Deep learning"}},{"citationKey":"mm2018-kato-songlesync","entryType":"inproceedings","entryTags":{"title":"Songle Sync: A Large-Scale Web-based Platform for Controlling Various Devices in Synchronization with Music","author":"Kato, Jun and Ogata, Masa and Inoue, Takahiro and Goto, Masataka","year":"2018","booktitle":"Proceedings of the 26th ACM International Conference on Multimedia","location":"Seoul, Republic of Korea","publisher":"ACM","address":"New York, NY, USA","series":"MM '18","pages":"1697--1705","doi":"10.1145/3240508.3240619","isbn":"978-1-4503-5665-7","numpages":"9","acmid":"3240619","keywords":"application programming interface, internet of musical things, multimedia control, music synchronization","project":"songle-sync","pdf":"https://junkato.jp/publications/mm2018-kato-songlesync.pdf","poster":"https://junkato.jp/publications/mm2018-kato-songlesync-poster.pdf","slides":"https://junkato.jp/publications/mm2018-kato-songlesync-slides.pdf"}},{"citationKey":"vlhcc2018-kato-deployground","entryType":"inproceedings","entryTags":{"title":"DeployGround: A Framework for Streamlined Programming from API playgrounds to Application Deployment","author":"Kato, Jun and Goto, Masataka","year":"2018","month":"oct","booktitle":"Proceedings of the 2018 IEEE Symposium on Visual Languages and Human-Centric Computing","publisher":"IEEE Computer Society","address":"Los Alamitos, CA, USA","series":"VL/HCC '18","pages":"259--263","doi":"10.1109/VLHCC.2018.8506562","issn":"1943-6106","numpages":"4","keywords":"Tutorials;Browsers;Encoding;Synchronization;Programming;Reactive power;Servers;Coding tutorials;online learning;API playground;live programming;programming experience","project":"deployground","pdf":"https://junkato.jp/publications/vlhcc2018-kato-deployground.pdf","slides":"https://junkato.jp/publications/vlhcc2018-kato-deployground-slides.pdf"}},{"citationKey":"dis2018-miyagawa-placing-music","entryType":"inproceedings","entryTags":{"title":"Placing Music in Space: A Study on Music Appreciation with Spatial Mapping","author":"Miyagawa, Shoki and Koyama, Yuki and Kato, Jun and Goto, Masataka and Morishima, Shigeo","year":"2018","booktitle":"Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems","location":"Hong Kong, China","publisher":"ACM","address":"New York, NY, USA","series":"DIS '18 Companion","pages":"39--43","doi":"10.1145/3197391.3205409","isbn":"978-1-4503-5631-2","url":"http://doi.acm.org/10.1145/3197391.3205409","acmid":"3205409","keywords":"augmented reality, music appreciation, spatial mapping"}},{"citationKey":"chi2018-suzuki-reactile","entryType":"inproceedings","entryTags":{"title":"Reactile: Programming Swarm User Interfaces Through Direct Physical Manipulation","author":"Suzuki, Ryo and Kato, Jun and Gross, Mark D. and Yeh, Tom","year":"2018","booktitle":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","location":"Montreal QC, Canada","publisher":"ACM","address":"New York, NY, USA","series":"CHI '18","pages":"199:1--199:13","doi":"10.1145/3173574.3173773","isbn":"978-1-4503-5620-6","url":"http://doi.acm.org/10.1145/3173574.3173773","articleno":"199","numpages":"13","acmid":"3173773","keywords":"direct manipulation, programming by demonstration, swarm user interfaces, tangible programming","projectsite":"https://ryosuzuki.org/reactile/","pdf":"https://ryosuzuki.org/publications/chi-2018-reactile.pdf","slides":"https://ryosuzuki.org/publications/chi-2018-reactile-slide.pdf","project":"reactile"}},{"citationKey":"live2017-kato-keynote","entryType":"misc","entryTags":{"title":"User Interfaces for Live Programming","author":"Kato, Jun","year":"2017","series":"LIVE '17","url":"https://2017.splashcon.org/details/live-2017/7/Keynote-User-Interfaces-for-Live-Programming","projectsite":"https://junkato.jp/live-programming","slides":"https://junkato.jp/publications/live2017-kato-keynote-slides.pdf","addition":"Keynote talk at LIVE '17","project":"live-programming"}},{"citationKey":"dis2017-kato-f3js","entryType":"inproceedings","entryTags":{"title":"F3.Js: A Parametric Design Tool for Physical Computing Devices for Both Interaction Designers and End-users","author":"Kato, Jun and Goto, Masataka","year":"2017","booktitle":"Proceedings of the 2017 Conference on Designing Interactive Systems","location":"Edinburgh, United Kingdom","publisher":"ACM","address":"New York, NY, USA","series":"DIS '17","pages":"1099--1110","doi":"10.1145/3064663.3064681","isbn":"978-1-4503-4922-2","url":"http://doi.acm.org/10.1145/3064663.3064681","numpages":"12","acmid":"3064681","keywords":"integrated development environment, parametric design, personal fabrication, physical computing","projectsite":"https://junkato.jp/f3js","pdf":"https://junkato.jp/publications/dis2017-kato-f3js.pdf","slides":"https://junkato.jp/publications/dis2017-kato-f3js-slides.pdf","project":"f3js"}},{"citationKey":"dagstuhl17232-kato","entryType":"article","entryTags":{"title":"The Future of Programming and Data Sciences","author":"Jun Kato","year":"2017","journal":"Dagstuhl Reports","booktitle":"Computational Interactivity (Dagstuhl Seminar 17232)","publisher":"Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik","address":"Dagstuhl, Germany","volume":"7","number":"6","pages":"56--56","doi":"10.4230/DagRep.7.6.48","issn":"2192-5283","url":"http://drops.dagstuhl.de/opus/volltexte/2017/8286","editor":"Xiaojun Bi and Otmar Hilliges and Takeo Igarashi and Antti Oulasvirta","urn":"urn:nbn:de:0030-drops-82865","annote":"Keywords: crowd-computing, graphics, HCI, Machine learning, optimization, simulation","projectsite":"http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=17232"}},{"citationKey":"smc2017-ojima-sing","entryType":"inproceedings","entryTags":{"title":"A Singing Instrument for Real-Time Vocal-Part Arrangement of Music and Audio Signals","author":"Ojima, Yuta and Nakano, Tomoyasu and Fukayama, Satoru and Kato, Jun and Goto, Masataka and Itoyama, Katsutoshi and Yoshii, Kazuyoshi","year":"2017","month":"jul","booktitle":"Proceedings of the 14th Sound and Music Computing Conference","series":"SMC '17","pages":"559--563","numpages":"5"}},{"citationKey":"px2017-kato-ugv","entryType":"inproceedings","entryTags":{"title":"User-Generated Variables: Streamlined Interaction Design for Feature Requests and Implementations","author":"Kato, Jun and Goto, Masataka","year":"2017","booktitle":"Companion to the First International Conference on the Art, Science and Engineering of Programming","location":"Brussels, Belgium","publisher":"ACM","address":"New York, NY, USA","series":"PX '17","pages":"28:1--28:7","doi":"10.1145/3079368.3079403","isbn":"978-1-4503-4836-2","url":"http://doi.acm.org/10.1145/3079368.3079403","articleno":"28","numpages":"7","acmid":"3079403","keywords":"User-generated content (UGC), integrated development environment, live programming, programming experience","projectsite":"https://junkato.jp/ugv","project":"user-generated-variables","pdf":"https://junkato.jp/publications/px2017-kato-user-generated-variables.pdf","relproject":"textalive,f3js"}},{"citationKey":"jnmr-smith-crosssong","entryType":"article","entryTags":{"title":"The CrossSong Puzzle: Developing a Logic Puzzle for Musical Thinking","author":"Jordan B.L. Smith and Jun Kato and Satoru Fukayama and Graham Percival and Masataka Goto","year":"2017","journal":"Journal of New Music Research","pages":"1--16","doi":"10.1080/09298215.2017.1303519","url":"http://dx.doi.org/10.1080/09298215.2017.1303519","numpages":"16","eprint":"http://dx.doi.org/10.1080/09298215.2017.1303519","projectsite":"https://staff.aist.go.jp/jun.kato/CrossSong","project":"crosssong"}},{"citationKey":"hri2017-kato-robocam","entryType":"inproceedings","entryTags":{"title":"A Robotic Framework for Video Recording and Authoring","author":"Kato, Jun and Goto, Masataka","year":"2017","booktitle":"Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","location":"Vienna, Austria","publisher":"ACM","address":"New York, NY, USA","series":"HRI '17 Companion","pages":"41--41","doi":"10.1145/3029798.3036666","isbn":"978-1-4503-4885-0","url":"http://doi.acm.org/10.1145/3029798.3036666","acmid":"3036666","keywords":"robotic camera system, toolkit., video authoring","projectsite":"http://logs.f3js.org","pdf":"https://junkato.jp/publications/hri2017-kato-robocam.pdf","project":"f3js"}},{"citationKey":"live2016-kato-livetuning","entryType":"inproceedings","entryTags":{"title":"Live Tuning: Expanding Live Programming Benefits to Non-Programmers","author":"Jun Kato and Masataka Goto","year":"2016","booktitle":"Proceedings of the Second Workshop on Live Programming Systems","location":"Rome, Italy","series":"LIVE '16","numpages":"6","projectsite":"https://junkato.jp/live-tuning","pdf":"https://junkato.jp/publications/live2016-kato-livetuning.pdf","poster":"https://junkato.jp/publications/live2016-kato-livetuning-poster.pdf","project":"live-tuning","relproject":"textalive,f3js"}},{"citationKey":"programming-with-examples","entryType":"article","entryTags":{"title":"Programming with Examples to Develop Data-Intensive User Interfaces","author":"Jun Kato and Takeo Igarashi and Masataka Goto","year":"2016","month":"jul","journal":"IEEE Computer","series":"Special Issue on 21st User Interfaces","volume":"49","number":"7","pages":"34--42","doi":"10.1109/MC.2016.217","issn":"0018-9162","numpages":"9","keywords":"Computer interfaces;Graphical user interfaces;Programming;Robot sensing systems;Software engineering;User interfaces;Videos;Visualization;DejaVu;GUI;IDE;Picode;TextAlive;integrated development environment;programming with examples;software development;software engineering;user interface design;user interfaces","projectsite":"https://junkato.jp/programming-with-examples","project":"programming-with-examples"}},{"citationKey":"iui2016-nakano-playlistplayer","entryType":"inproceedings","entryTags":{"title":"PlaylistPlayer: An Interface Using Multiple Criteria to Change the Playback Order of a Music Playlist","author":"Nakano, Tomoyasu and Kato, Jun and Hamasaki, Masahiro and Goto, Masataka","year":"2016","booktitle":"Proceedings of the 21st International Conference on Intelligent User Interfaces","location":"Sonoma, California, USA","publisher":"ACM","address":"New York, NY, USA","series":"IUI '16","pages":"186--190","doi":"10.1145/2856767.2856809","isbn":"978-1-4503-4137-0","url":"http://doi.acm.org/10.1145/2856767.2856809","numpages":"5","acmid":"2856809","keywords":"music playlist, musical commonness, playback order, social commonness, visualization, vocal gender","project":"playlistplayer"}},{"citationKey":"uist2015-kato-f3js-demo","entryType":"inproceedings","entryTags":{"title":"Form Follows Function(): An IDE to Create Laser-cut Interfaces and Microcontroller Programs from Single Code Base","author":"Kato, Jun and Goto, Masataka","year":"2015","booktitle":"Adjunct Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology","location":"Charlotte, NC, USA","publisher":"ACM","address":"New York, NY, USA","series":"UIST '15 Adjunct","pages":"43--44","doi":"10.1145/2815585.2817797","isbn":"978-1-4503-3780-9","url":"http://doi.acm.org/10.1145/2815585.2817797","acmid":"2817797","keywords":"integrated development environment, laser-cut interface, microcontroller, personal fabrication","pdf":"https://junkato.jp/publications/uist2015-kato-f3js-demo.pdf","project":"f3js"}},{"citationKey":"smc2015-smith-crosssong","entryType":"inproceedings","entryTags":{"title":"CrossSong Puzzle: Generating and Unscrambling Music Mash-ups with Real-time Interactivity","author":"Jordan Smith and Graham Parcival and Jun Kato and Masataka Goto and Satoru Fukayama","year":"2015","month":"jul","booktitle":"Proceedings of the 12nd Sound and Music Computing Conference","location":"Maynooth, Ireland","series":"SMC '15","pages":"61--67","numpages":"7","keywords":"mashups, games, puzzles, interaction","pdf":"https://staff.aist.go.jp/jun.kato/CrossSong/smc2015-smith-crosssong.pdf","addition":"SMC '15 Best Paper Award","projectsite":"https://staff.aist.go.jp/jun.kato/CrossSong","project":"crosssong"}},{"citationKey":"iclc2015-kato-textalive","entryType":"inproceedings","entryTags":{"title":"TextAlive Online: Live Programming of Kinetic Typography Videos with Online Music","author":"Jun Kato and Tomoyasu Nakano and Masataka Goto","year":"2015","month":"jul","booktitle":"Proceedings of the First International Conference on Live Coding","location":"Leeds, UK","publisher":"ICSRiM, University of Leeds","series":"ICLC '15","pages":"199--205","doi":"10.5281/zenodo.19355","url":"http://dx.doi.org/10.5281/zenodo.19355","numpages":"6","project":"textalive"}},{"citationKey":"chi2015-kato-textalive","entryType":"inproceedings","entryTags":{"title":"TextAlive: Integrated Design Environment for Kinetic Typography","author":"Kato, Jun and Nakano, Tomoyasu and Goto, Masataka","year":"2015","booktitle":"Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems","location":"Seoul, Republic of Korea","publisher":"ACM","address":"New York, NY, USA","series":"CHI '15","pages":"3403--3412","doi":"10.1145/2702123.2702140","isbn":"978-1-4503-3145-6","url":"http://doi.acm.org/10.1145/2702123.2702140","numpages":"10","acmid":"2702140","keywords":"animation, creativity support tool, integrated design environment, kinetic typography, live programming","pdf":"https://junkato.jp/publications/chi2015-kato-textalive.pdf","slides":"https://junkato.jp/publications/chi2015-kato-textalive-slides.pdf","addition":"ACM CHI '15 Honorable Mention Award","project":"textalive"}},{"citationKey":"hai2014-kato-sharedo","entryType":"inproceedings","entryTags":{"title":"Sharedo: To-do List Interface for Human-agent Task Sharing","author":"Kato, Jun and Sakamoto, Daisuke and Igarashi, Takeo and Goto, Masataka","year":"2014","booktitle":"Proceedings of the Second International Conference on Human-Agent Interaction","location":"Tsukuba, Japan","publisher":"ACM","address":"New York, NY, USA","series":"HAI '14","pages":"345--351","doi":"10.1145/2658861.2658894","isbn":"978-1-4503-3035-0","url":"http://doi.acm.org/10.1145/2658861.2658894","numpages":"7","acmid":"2658894","keywords":"human-robot interaction, social media platforms, to-do list","pdf":"https://junkato.jp/publications/hai2014-kato-sharedo.pdf","slides":"https://junkato.jp/publications/hai2014-kato-sharedo-slides.pdf","addition":"HAI '14 Best Paper Nominee","project":"sharedo"}},{"citationKey":"gi2014-kato-visionsketch","entryType":"inproceedings","entryTags":{"title":"VisionSketch: Integrated Support for Example-centric Programming of Image Processing Applications","author":"Kato, Jun and Igarashi, Takeo","year":"2014","booktitle":"Proceedings of the 2014 Graphics Interface Conference","location":"Montreal, Quebec, Canada","publisher":"Canadian Information Processing Society","address":"Toronto, Ontario, Canada","series":"GI '14","pages":"115--122","isbn":"978-1-4822-6003-8","url":"http://dl.acm.org/citation.cfm?id=2619648.2619668","numpages":"8","acmid":"2619668","keywords":"computer vision, example-centric programming, image processing, integrated development environment","pdf":"https://junkato.jp/publications/gi2014-kato-visionsketch.pdf","slides":"https://junkato.jp/publications/gi2014-kato-visionsketch-slides.pdf","project":"visionsketch","affiliation":"The University of Tokyo"}},{"citationKey":"chi2014-fukahori-capstudio","entryType":"inproceedings","entryTags":{"title":"CapStudio: An Interactive Screencast for Visual Application Development","author":"Fukahori, Koumei and Sakamoto, Daisuke and Kato, Jun and Igarashi, Takeo","year":"2014","booktitle":"Extended Abstracts on Human Factors in Computing Systems","location":"Toronto, Ontario, Canada","publisher":"ACM","address":"New York, NY, USA","series":"CHI EA '14","pages":"1453--1458","doi":"10.1145/2559206.2581138","isbn":"978-1-4503-2474-8","url":"http://doi.acm.org/10.1145/2559206.2581138","numpages":"6","acmid":"2581138","keywords":"design alternatives, development environment, live programming","pdf":"http://www-ui.is.s.u-tokyo.ac.jp/~fukahori/capstudio/CHI_WIP_cameraready2.pdf","poster":"https://junkato.jp/publications/chi2014-fukahori-capstudio-poster.pdf","project":"capstudio","affiliation":"The University of Tokyo"}},{"citationKey":"phd-dissertation-kato","entryType":"phdthesis","entryTags":{"title":"Integrated Graphical Representations for Development of Programs with Real-world Input and Output","author":"Kato, Jun","year":"2014","month":"mar","type":"dissertation","pdf":"http://hdl.handle.net/2261/58372"}},{"citationKey":"uist2013-kato","entryType":"inproceedings","entryTags":{"title":"Integrated Visual Representations for Programming with Real-world Input and Output","author":"Kato, Jun","year":"2013","booktitle":"Adjunct Proceedings of the 26th Annual ACM symposium on User Interface Software and Technology","location":"St. Andrews, Scotland, United Kingdom","publisher":"ACM","address":"New York, NY, USA","series":"UIST '15 Adjunct (Doctoral Symposium)","pages":"57--60","doi":"10.1145/2508468.2508476","isbn":"978-1-4503-2406-9","url":"http://doi.acm.org/10.1145/2508468.2508476","acmid":"2508476","keywords":"development environment, real-world input and output","pdf":"https://junkato.jp/publications/uist2013-kato.pdf","poster":"https://junkato.jp/publications/uist2013-kato-poster.pdf","project":"pwe"}},{"citationKey":"gcce2013-kato-openpool","entryType":"inproceedings","entryTags":{"title":"OpenPool: Community-based Prototyping of Digitally-augmented Billiard Table","author":"Kato, Jun and Nakashima, Takashi and Takeoka, Hideki and Ogasawara, Kazunori and Murao, Kazuma and Shimokawa, Toshinari and Sugimoto, Masaaki","year":"2013","month":"oct","booktitle":"Proceedings of the 2nd IEEE Global Conference on Consumer Electronics","series":"IEEE GCCE '13","pages":"175--176","doi":"10.1109/GCCE.2013.6664790","url":"http://dx.doi.org/10.1109/GCCE.2013.6664790","keywords":"augmented sports, community-based prototyping, entertainment computing, open-source software and hardware","numpages":"2","pdf":"https://junkato.jp/publications/gcce2013-kato-openpool.pdf","slides":"https://junkato.jp/publications/gcce2013-kato-openpool-slides.pdf","project":"openpool"}},{"citationKey":"pldi2013-kato-visionsketch","entryType":"inproceedings","entryTags":{"title":"Visionsketch: Gesture-based Language for End-user Computer Vision Programming","author":"Kato, Jun","year":"2013","month":"jun","booktitle":"The 34th ACM SIGPLAN Conference on Programming Language Design and Implementation","series":"Student Research Competition at PLDI '13","projectsite":"https://junkato.jp/visionsketch","pdf":"https://junkato.jp/publications/pldi2013-kato-visionsketch.pdf","slides":"https://junkato.jp/publications/pldi2013-kato-visionsketch-slides.pdf","poster":"https://junkato.jp/publications/pldi2013-kato-visionsketch-poster.pdf","addition":"ACM PLDI '13 Student Research Competition Finalist","project":"visionsketch"}},{"citationKey":"pldi2013-kato-alive","entryType":"inproceedings","entryTags":{"title":"It's Alive! Continuous Feedback in UI Programming","author":"Burckhardt, Sebastian and Fahndrich, Manuel and de Halleux, Peli and McDirmid, Sean and Moskal, Michal and Tillmann, Nikolai and Kato, Jun","year":"2013","booktitle":"Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation","location":"Seattle, Washington, USA","publisher":"ACM","address":"New York, NY, USA","series":"PLDI '13","pages":"95--104","doi":"10.1145/2491956.2462170","isbn":"978-1-4503-2014-6","url":"http://doi.acm.org/10.1145/2491956.2462170","numpages":"10","acmid":"2462170","keywords":"graphical user interface, live programming","projectsite":"https://junkato.jp/touchdevelop","pdf":"http://research.microsoft.com/apps/pubs/default.aspx?id=189242","slides":"http://research.microsoft.com/apps/pubs/default.aspx?id=189242","project":"touchdevelop"}},{"citationKey":"chi2013-kato-picode","entryType":"inproceedings","entryTags":{"title":"Picode: Inline Photos Representing Posture Data in Source Code","author":"Kato, Jun and Sakamoto, Daisuke and Igarashi, Takeo","year":"2013","month":"apr","booktitle":"Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","location":"Paris, France","series":"CHI '13","pages":"3097--3100","doi":"10.1145/2470654.2466422","isbn":"978-1-4503-1899-0","url":"http://doi.acm.org/10.1145/2470654.2466422","numpages":"4","acmid":"2466422","keywords":"development environment, inline photo, posture data","projectsite":"https://junkato.jp/picode","pdf":"https://junkato.jp/publications/chi2013-kato-picode.pdf","slides":"https://junkato.jp/publications/chi2013-kato-picode-slides.pdf","addition":"ACM CHI '13 Honorable Mention Award","project":"picode"}},{"citationKey":"uist2012-kato-dejavu","entryType":"inproceedings","entryTags":{"title":"DejaVu: Integrated Support for Developing Interactive Camera-Based Programs","author":"Kato, Jun and McDirmid, Sean and Cao, Xiang","year":"2012","month":"oct","booktitle":"Proceedings of the 25th Annual ACM symposium on User Interface Software and Technology","location":"Cambridge, Massachusetts, USA","publisher":"ACM","address":"New York, NY, USA","series":"UIST '12","pages":"189--196","doi":"10.1145/2380116.2380142","isbn":"978-1-4503-1580-7","url":"http://doi.acm.org/10.1145/2380116.2380142","numpages":"8","acmid":"2380142","keywords":"computer vision, development environment","projectsite":"https://junkato.jp/dejavu","pdf":"https://junkato.jp/publications/uist2012-kato-dejavu.pdf","poster":"https://junkato.jp/publications/uist2012-kato-dejavu-poster.pdf","slides":"https://junkato.jp/publications/uist2012-kato-dejavu-slides.pdf","project":"dejavu"}},{"citationKey":"dis2012-kato-phybots","entryType":"inproceedings","entryTags":{"title":"Phybots: A Toolkit for Making Robotic Things","author":"Kato, Jun and Sakamoto, Daisuke and Igarashi, Takeo","year":"2012","month":"jun","booktitle":"Proceedings of the 9th Conference on Designing Interactive Systems","location":"Newcastle Upon Tyne, United Kingdom","publisher":"ACM","address":"New York, NY, USA","series":"DIS '12","pages":"248--257","doi":"10.1145/2317956.2317996","isbn":"978-1-4503-1210-3","url":"http://doi.acm.org/10.1145/2317956.2317996","numpages":"10","acmid":"2317996","keywords":"prototyping, robotic things, toolkits","projectsite":"http://phybots.com","pdf":"https://junkato.jp/publications/dis2012-kato-phybots.pdf","slides":"https://junkato.jp/publications/dis2012-kato-phybots-slides.pdf","project":"phybots"}},{"citationKey":"uist2010-kato-surfboard","entryType":"inproceedings","entryTags":{"title":"Surfboard: Keyboard with Microphone as a Low-cost Interactive Surface","author":"Kato, Jun and Sakamoto, Daisuke and Igarashi, Takeo","year":"2010","month":"oct","booktitle":"Adjunct Proceedings of the 23rd Annual ACM Symposium on User Interface Software and Technology","location":"New York, New York, USA","publisher":"ACM","address":"New York, NY, USA","series":"UIST '10 Adjunct","pages":"387--388","doi":"10.1145/1866218.1866233","isbn":"978-1-4503-0462-7","url":"http://doi.acm.org/10.1145/1866218.1866233","projectsite":"https://junkato.jp/surfboard","poster":"https://junkato.jp/publications/uist2010-kato-surfboard-poster.pdf","pdf":"https://junkato.jp/publications/uist2010-kato-surfboard.pdf","project":"surfboard"}},{"citationKey":"uist2009-kato-andy","entryType":"inproceedings","entryTags":{"title":"A Toolkit for Easy Development of Mobile Robot Applications with Visual Markers and a Ceiling Camera","author":"Sakamoto, Daisuke and Kato, Jun and Inami, Masahiko and Igarashi, Takeo","year":"2009","month":"oct","booktitle":"The 22nd Annual ACM Symposium on User Interface Software and Technology","location":"Victoria, BC, Canada","series":"UIST '09 Demo","projectsite":"http://phybots.com","pdf":"https://junkato.jp/publications/uist2009-sakamoto-andy.pdf","project":"phybots"}},{"citationKey":"siggraph2009-kato-cristal","entryType":"inproceedings","entryTags":{"title":"CRISTAL, Control of Remotely Interfaced Systems using Touch-based Actions in Living Spaces","author":"Seifried, Thomas and Rendl, Christian and Perteneder, Florian and Leitner, Jakob and Haller, Michael and Sakamoto, Daisuke and Kato, Jun and Inami, Masahiko and Scott, Stacey D.","year":"2009","month":"aug","booktitle":"ACM SIGGRAPH 2009 Emerging Technologies","location":"New Orleans, Louisiana","publisher":"ACM","address":"New York, NY, USA","series":"SIGGRAPH '09 E-Tech","doi":"10.1145/1597956.1597962","isbn":"978-1-60558-833-9","url":"http://doi.acm.org/10.1145/1597956.1597962","addition":"Laval Virtual Award (SIGGRAPH '09 Best of E-Tech)","projectsite":"http://designinterface.jp/en/projects/CRISTAL","pdf":"http://designinterface.jp/projects/CRISTAL/cristal-2009.pdf","project":"cristal"}},{"citationKey":"chi2009-kato-multirobot","entryType":"inproceedings","entryTags":{"title":"Multi-touch Interface for Controlling Multiple Mobile Robots","author":"Kato, Jun and Sakamoto, Daisuke and Inami, Masahiko and Igarashi, Takeo","year":"2009","month":"apr","booktitle":"Extended Abstracts on Human Factors in Computing Systems","location":"Boston, MA, USA","publisher":"ACM","address":"New York, NY, USA","series":"CHI EA '09","pages":"3443--3448","doi":"10.1145/1520340.1520500","isbn":"978-1-60558-247-4","url":"http://doi.acm.org/10.1145/1520340.1520500","numpages":"6","addition":"ACM CHI '09 Student Research Competition 1st Place","projectsite":"http://src.acm.org/2010/JunKato/srcgf10-jun","pdf":"https://junkato.jp/publications/chi2009-kato-multirobot.pdf","slides":"https://junkato.jp/publications/chi2009-kato-multirobot-slides.pdf","poster":"https://junkato.jp/publications/chi2009-kato-multirobot-poster.pdf","project":"multirobot"}},{"entryType":"COMMENT","entry":"com3,memo={Domesticpublicationsfollows.}"},{"citationKey":"media2024autumn-kato-computer-history-practice","entryType":"unpublished","entryTags":{"title":"コンピュータをどう考え、どう作るか Human-Computer Interaction研究の視点","author":"加藤 淳","year":"2024","month":"oct","booktitle":"日本メディア学会 2024年秋季大会 (JAMS Fall 2024 Conference)","note":"ワークショップ 10. 「コンピュータの歴史と実践」セッション","slides":"https://junkato.jp/publications/media2024autumn-kato-slides.pdf","language":"japanese"}},{"citationKey":"vc2024-kato-toolsmiths-in-anime","entryType":"inproceedings","entryTags":{"title":"3DCGアニメーション向けの実用的なスタイル転写: 映像制作のためのR&D実践","author":"藤堂 英樹 and 小山 裕己 and 酒井 邦博 and 小宮 彬広 and 加藤 淳","year":"2024","month":"sep","series":"VC '24","addition":"VCポスター賞","affiliation":"Arch Inc.","language":"japanese"}},{"citationKey":"interaction2024-kato-lyric-app-framework","entryType":"inproceedings","entryTags":{"title":"Lyric App Framework: インタラクティブな歌詞駆動型視覚表現の開発用フレームワーク","author":"加藤 淳 and 後藤 真孝","year":"2024","month":"mar","booktitle":"インタラクション2024論文集","publisher":"Information Processing Society of Japan (IPSJ)","series":"インタラクション '24","pages":"1--10","projectsite":"https://junkato.jp/ja/lyric-app-framework","pdf":"https://junkato.jp/publications/interaction2024-kato-lyric-apps.pdf","slides":"https://junkato.jp/publications/interaction2024-kato-lyric-apps-slides.pdf","language":"japanese","addition":"インタラクション '24 最優秀論文賞; インタラクション '24 インタラクティブ発表賞（一般投票）","project":"lyric-app-framework"}},{"citationKey":"sigmus138-kato-lyric-app-framework","entryType":"techreport","entryTags":{"title":"TextAlive App API:「リリックアプリ」の提案とプログラミング・コンテストでの実証実験","author":"加藤 淳 and 後藤 真孝","year":"2023","month":"aug","booktitle":"音楽情報科学 研究報告","publisher":"情報処理学会","series":"SIGMUS 138","volume":"2023-MUS-138","number":"7","pages":"1--21","issn":"2188-8752","url":"http://id.nii.ac.jp/1001/00227237/","addition":"SIGMUS 138 ベストプレゼンテーション賞 (Best Research部門)","language":"japanese","pdf":"https://junkato.jp/publications/sigmus138-kato-lyric-apps.pdf","slides":"https://junkato.jp/publications/sigmus138-kato-lyric-apps-slides.pdf","project":"lyric-app-framework"}},{"citationKey":"hi25-kato-ui-design-for-authoring-videos","entryType":"article","entryTags":{"title":"動画をつくるためのインタフェースデザイン","author":"加藤 淳","year":"2023","month":"may","journal":"ヒューマンインタフェース学会誌","volume":"25","number":"2","pages":"12--15","abstract":"私たちの日々の生活は動画で彩られている。そして、動画制作も、もはや一握りのプロが高価な機材で取り組むものではなくなってきている。その要因として、本稿では、ソフトウェアの動画制作ツールが使いやすい動画制作支援インタフェースを備えるようになってきたことに注目したい。とくに、著者がこれまで取り組んできた音楽動画やアニメの制作支援研究の知見も織り交ぜながら、快適な動画制作を支えるインタフェースデザインの一端を紹介する。そして、インタフェースデザインがクリエータ同士の共創を後押しすることの重要性について述べる。","numpages":"4","addition":"特集: つくる、みる、きくエンタテインメント","language":"japanese"}},{"citationKey":"ipsj64-5-kato-chi2022-seminar-report","entryType":"article","entryTags":{"title":"CHI勉強会2022 開催報告 & 2023のご案内","author":"加藤 淳","year":"2023","month":"apr","journal":"情報処理","volume":"64","number":"5","pages":"252--256","doi":"10.20729/00225538","url":"http://doi.org/10.20729/00225538","language":"japanese"}},{"citationKey":"ipsj63-5-kato-siggraph-asia-2021-report","entryType":"article","entryTags":{"title":"SIGGRAPH Asia 2021「Real-Time Live!」レポート","author":"加藤 淳","year":"2022","month":"apr","journal":"情報処理","volume":"63","number":"5","pages":"264--265","doi":"10.20729/00217591","url":"http://doi.org/10.20729/00217591","language":"japanese"}},{"citationKey":"jssst39-1-kato-toolsmith","entryType":"article","entryTags":{"title":"道具鍛冶職人の楽しみ","author":"加藤 淳","year":"2022","journal":"コンピュータ ソフトウェア","volume":"39","number":"1","pages":"84--85","doi":"10.11309/jssst.39.1_84","url":"https://doi.org/10.11309/jssst.39.1_84","language":"japanese"}},{"citationKey":"ipsj62-10-kato-ipsj-acm-award","entryType":"article","entryTags":{"title":"プログラミングとコンテンツの未来のための研究","author":"加藤 淳","year":"2021","month":"oct","journal":"情報処理","volume":"62","number":"10","pages":"547--547","doi":"10.20729/00212783","url":"http://doi.org/10.20729/00212783","language":"japanese"}},{"citationKey":"eureka2021-9-kato-tachibana","entryType":"article","entryTags":{"title":"立花先生と情報技術","author":"加藤 淳","year":"2021","month":"sep","booktitle":"ユリイカ2021年9月号 特集＝立花隆 ―1940-2021―","volume":"53","number":"10","pages":"152--159","url":"https://iss.ndl.go.jp/books/R000000004-I031703139-00","group":"「調べて書く」ために","projectsite":"http://www.seidosha.co.jp/book/index.php?id=3602","language":"japanese"}},{"citationKey":"asj-v77n4-kato-ui-design","entryType":"article","entryTags":{"title":"インタフェース・デザインの勘所","author":"加藤 淳","year":"2021","journal":"日本音響学会誌","volume":"77","number":"4","pages":"231--238","doi":"10.20697/jasj.77.4_231","url":"https://doi.org/10.20697/jasj.77.4_231","project":"user-interface-design","language":"japanese"}},{"citationKey":"ipsj-v61n1-kato-canna","entryType":"article","entryTags":{"title":"2. 貴方の考える未来社会像: 2.6. カンナたちの研究","author":"加藤 淳","year":"2019","month":"dec","journal":"情報処理","volume":"61","number":"1","pages":"36--40","url":"http://id.nii.ac.jp/1001/00201049/","group":"『AIの遺電子』に学ぶ未来構想術","project":"science","language":"japanese"}},{"citationKey":"ipsj-v61n1-discussions","entryType":"article","entryTags":{"title":"3. 講評会: 山田胡瓜先生を囲んで","author":"山田 胡瓜 and 福地 健太郎 and 大澤 博隆 and 宮本 道人 and 江渡 浩一郎 and 倉本 到 and 渡邊 淳司 and 前田 太郎 and 中村 裕美 and 寺島 裕貴 and 加藤 淳 and 米澤 朋子 and 塩見 昌裕 and 新山 龍馬 and 宮本 隆史 and 水野 雄太 and 櫻井 翔","year":"2019","month":"dec","journal":"情報処理","volume":"61","number":"1","pages":"71--77","url":"http://id.nii.ac.jp/1001/00201057/","group":"『AIの遺電子』に学ぶ未来構想術","project":"science","language":"japanese"}},{"citationKey":"joss2019-kato","entryType":"unpublished","entryTags":{"title":"非アカデミア駆動型研究の 2 類型","author":"加藤 淳","year":"2019","month":"may","booktitle":"Japan Open Science Summit","series":"JOSS 2019","note":"B2 非アカデミア駆動型研究の潮流と可能性」セッション","slides":"https://junkato.jp/publications/joss2019-kato-slides.pdf","language":"japanese","project":"science"}},{"citationKey":"hi20-kato-reproducibility","entryType":"article","entryTags":{"title":"ヒューマンインタフェース研究における再現性向上に向けた取り組み","author":"加藤 淳","year":"2018","month":"feb","journal":"ヒューマンインタフェース学会誌","volume":"20","number":"1","pages":"23--28","numpages":"6","addition":"特集: 研究再現性問題","projectsite":"https://junkato.jp/ja/science","pdf":"https://junkato.jp/publications/hi20-kato-reproducibility.pdf","project":"science","language":"japanese"}},{"citationKey":"sigmus118-ogata-songlesync","entryType":"techreport","entryTags":{"title":"Songle Sync: 音楽に連動させて多様なデバイスを大規模に制御できるプラットフォーム","author":"尾形 正泰 and 井上 隆広 and 加藤 淳 and 後藤 真孝","year":"2018","month":"feb","booktitle":"音楽情報科学 研究報告","publisher":"情報処理学会","series":"SIGMUS 118","volume":"2018-MUS-118","number":"9","pages":"1--12","issn":"2188-8752","url":"http://id.nii.ac.jp/1001/00185686/","language":"japanese","project":"songle-sync"}},{"citationKey":"ipsj-v58n11-px-introduction","entryType":"article","entryTags":{"title":"0. 編集にあたって","author":"加藤 淳 and 増原 英彦","year":"2017","month":"oct","journal":"情報処理","volume":"58","number":"11","pages":"1006--1009","url":"http://id.nii.ac.jp/1001/00183678/","group":"プログラミング・エクスペリエンスの新潮流 -言語設計から産業応用まで-","language":"japanese"}},{"citationKey":"ipsj-v58n11-px-live-programming","entryType":"article","entryTags":{"title":"1. ライブプログラミングによる滑らかなプログラミング体験","author":"Sean McDirmid and 加藤 淳","year":"2017","month":"oct","journal":"情報処理","volume":"58","number":"11","pages":"1010--1011","url":"http://id.nii.ac.jp/1001/00183679/","group":"プログラミング・エクスペリエンスの新潮流 -言語設計から産業応用まで-","language":"japanese"}},{"citationKey":"sigmus116-nakano-texttimeline","entryType":"techreport","entryTags":{"title":"TextTimeline: 文字表示を保持した発話テキストの音響特徴可視化","author":"中野 倫靖 and 加藤 淳 and 後藤 真孝","year":"2017","month":"aug","booktitle":"音楽情報科学 研究報告","publisher":"情報処理学会","series":"SIGMUS 116","volume":"2017-MUS-116","number":"21","pages":"1--7","issn":"2188-8752","url":"http://id.nii.ac.jp/1001/00182966/","language":"japanese"}},{"citationKey":"sigmus116-ojima-keyboard","entryType":"techreport","entryTags":{"title":"既存歌唱曲アレンジのための歌声キーボード","author":"尾島 優太 and 中野 倫靖 and 深山 覚 and 加藤 淳 and 後藤 真孝 and 糸山 克寿 and 吉井 和佳","year":"2017","month":"aug","booktitle":"音楽情報科学 研究報告","publisher":"情報処理学会","series":"SIGMUS 116","volume":"2017-MUS-116","number":"4","pages":"1--7","issn":"2188-8752","url":"http://id.nii.ac.jp/1001/182949/","language":"japanese"}},{"citationKey":"sighci174-matsumura-chi2017-seminar","entryType":"techreport","entryTags":{"title":"CHI勉強会2017：ネットワーク連携した勉強会とその支援システム","author":"松村 耕平 and 尾形 正泰 and 小野 哲雄 and 加藤 淳 and 阪口 紗季 and 坂本 大介 and 杉本 雅則 and 角 康之 and 中村 裕美 and 西田 健志 and 樋口 啓太 and 安尾 萌 and 渡邉 拓貴","year":"2017","month":"aug","booktitle":"ヒューマンコンピュータインタラクション 研究報告","publisher":"情報処理学会","series":"SIGHCI 174","volume":"2017-HCI-174","number":"13","pages":"1--8","issn":"2188-8760","url":"http://id.nii.ac.jp/1001/00182981/","language":"japanese"}},{"citationKey":"ipsjz79-ojima-keyboard","entryType":"techreport","entryTags":{"title":"既存歌唱曲のリアルタイム歌声アレンジシステム","author":"尾島 優太 and 中野 倫靖 and 深山 覚 and 加藤 淳 and 後藤 真孝 and 糸山 克寿 and 吉井 和佳","year":"2017","month":"mar","booktitle":"第79回全国大会講演論文集","publisher":"情報処理学会","volume":"2017","number":"1","pages":"127--128","url":"http://id.nii.ac.jp/1001/00180748/","language":"japanese"}},{"citationKey":"sigmus112-hara-djcoder","entryType":"techreport","entryTags":{"title":"DJCoder: DJシステムと密に連携したプログラミング環境","author":"原 健太 and 加藤 淳 and 後藤 真孝","year":"2016","month":"jul","booktitle":"音楽情報科学 研究報告","publisher":"情報処理学会","series":"SIGMUS 112","volume":"2016-MUS-112","number":"8","pages":"1--7","issn":"2188-8752","url":"http://id.nii.ac.jp/1001/00170518/","pdf":"https://junkato.jp/publications/sigmus112-hara-djcoder.pdf","language":"japanese"}},{"citationKey":"interaction2016-kato-f3js","entryType":"inproceedings","entryTags":{"title":"IoTアプリケーションのソフトウェア・ハードウェアを単一コードベースで開発できる統合開発環境f3.js","author":"加藤 淳 and 後藤 真孝","year":"2016","month":"mar","booktitle":"インタラクション2016論文集","publisher":"Information Processing Society of Japan (IPSJ)","series":"インタラクション '16","pages":"132--139","projectsite":"https://junkato.jp/ja/f3js","pdf":"https://junkato.jp/publications/interaction2016-kato-f3js.pdf","slides":"https://junkato.jp/publications/interaction2016-kato-f3js-slides.pdf","language":"japanese","project":"f3js"}},{"citationKey":"ipsj56-7-kato-chi2015-report","entryType":"article","entryTags":{"title":"CHI 2015 参加報告","author":"加藤 淳","year":"2015","month":"jun","journal":"情報処理","volume":"56","number":"7","pages":"698--699","url":"http://id.nii.ac.jp/1001/00142321/","language":"japanese"}},{"citationKey":"spro2014-kato-live-programming","entryType":"techreport","entryTags":{"title":"実世界Live Programmingの実現に向けて","author":"加藤 淳","year":"2015","month":"jan","booktitle":"夏のプログラミング・シンポジウム2014「ビューティフル・インターフェイス」報告集","publisher":"情報処理学会","volume":"2014","pages":"51--58","url":"http://id.nii.ac.jp/1001/00146635/","pdf":"https://junkato.jp/publications/spro2014-kato-live-beautified.pdf","language":"japanese","project":"live-programming"}},{"citationKey":"wiss2014-kato-textalive","entryType":"inproceedings","entryTags":{"title":"TextAlive: インタラクティブでプログラマブルなKinetic Typography制作環境","author":"加藤 淳 and 中野 倫靖 and 後藤 真孝","year":"2014","month":"nov","booktitle":"第22回インタラクティブシステムとソフトウェアに関するワークショップ","publisher":"日本ソフトウェア科学会","series":"WISS '14","volume":"2014","number":"15","pages":"39--44","issn":"","url":"http://ci.nii.ac.jp/naid/110009815122/en/","projectsite":"https://staff.aist.go.jp/jun.kato/TextAlive","pdf":"https://junkato.jp/publications/wiss2014-kato-textalive.pdf","slides":"https://junkato.jp/publications/wiss2014-kato-textalive-slides.pdf","addition":"WISS '14 最優秀論文賞","language":"japanese","project":"textalive"}},{"citationKey":"sigmus104-kato-textalive","entryType":"techreport","entryTags":{"title":"TextAlive:音楽に同期した歌詞アニメーションのKinetic Typography制作環境","author":"加藤 淳 and 中野 倫靖 and 後藤 真孝","year":"2014","month":"aug","booktitle":"音楽情報科学 研究報告","publisher":"情報処理学会","series":"SIGMUS 104","volume":"2014-MUS-104","number":"15","pages":"1--7","url":"http://id.nii.ac.jp/1001/00102532/","addition":"SIGMUS 104 ベストプレゼンテーション賞","language":"japanese","pdf":"https://junkato.jp/publications/sigmus104-kato-lyric-apps.pdf","slides":"https://junkato.jp/publications/sigmus104-kato-lyric-apps-slides.pdf","project":"textalive"}},{"citationKey":"wiss2012-kato-roboko","entryType":"inproceedings","entryTags":{"title":"Roboko: ソースコードに写真を貼り込める統合開発環境","author":"加藤 淳 and 坂本 大介 and 五十嵐 健夫","year":"2012","month":"dec","booktitle":"第20回インタラクティブシステムとソフトウェアに関するワークショップ","publisher":"日本ソフトウェア科学会","series":"WISS '12","pages":"115--120","projectsite":"https://junkato.jp/ja/picode","pdf":"https://junkato.jp/publications/wiss2012-kato-roboko.pdf","slides":"https://junkato.jp/publications/wiss2012-kato-roboko-slides.pdf","language":"japanese","project":"picode"}},{"citationKey":"wiss2011-kato-sharedo","entryType":"inproceedings","entryTags":{"title":"Sharedo: To-doリストによる人-ロボット間のタスク共有","author":"加藤 淳 and 坂本 大介 and 五十嵐 健夫","year":"2011","month":"dec","booktitle":"第19回インタラクティブシステムとソフトウェアに関するワークショップ","publisher":"日本ソフトウェア科学会","series":"WISS '11","pages":"102--107","projectsite":"http://sharedo.digitalmuseum.jp/research/wiss2011","pdf":"https://junkato.jp/publications/wiss2011-kato-sharedo.pdf","slides":"https://junkato.jp/publications/wiss2011-kato-sharedo-slides.pdf","language":"japanese","project":"sharedo"}},{"citationKey":"wiss2010-kato-matereal","entryType":"inproceedings","entryTags":{"title":"matereal: インタラクティブなロボットアプリケーションのプロトタイピング用ツールキット","author":"加藤 淳 and 坂本 大介 and 五十嵐 健夫","year":"2010","month":"dec","booktitle":"第18回インタラクティブシステムとソフトウェアに関するワークショップ","publisher":"日本ソフトウェア科学会","series":"WISS '10","pages":"83--88","projectsite":"http://phybots.com/jp","pdf":"https://junkato.jp/publications/wiss2010-kato-matereal.pdf","slides":"https://junkato.jp/publications/wiss2010-kato-matereal-slides.pdf","language":"japanese","project":"phybots"}},{"citationKey":"interaction2010-kato-pressing","entryType":"inproceedings","entryTags":{"title":"Pressing: 打鍵の強さで出力が変わるビジュアルインタプリタ","author":"加藤 淳 and 五十嵐 健夫","year":"2010","month":"mar","booktitle":"インタラクション2010","publisher":"Information Processing Society of Japan (IPSJ)","series":"インタラクション2010デモ","pages":"191--192","projectsite":"https://junkato.jp/ja/pressing","pdf":"https://junkato.jp/publications/interaction2010-kato-pressing.pdf","poster":"https://junkato.jp/publications/interaction2010-kato-pressing-poster.pdf","language":"japanese","project":"pressing"}},{"citationKey":"wpro2010-kato-matereal","entryType":"techreport","entryTags":{"title":"matereal：小型移動ロボットを用いたアプリケーション制作用ツールキットの開発","author":"加藤 淳 and 坂本 大介 and 五十嵐 健夫","year":"2010","month":"jan","booktitle":"第51回プログラミング・シンポジウム予稿集","publisher":"情報処理学会","volume":"2010","pages":"29--36","url":"http://id.nii.ac.jp/1001/00091427/","language":"japanese","project":"phybots"}},{"citationKey":"ipsj52-kato-andy","entryType":"article","entryTags":{"title":"Andy: 俯瞰カメラとマーカを用いた移動ロボットアプリケーション開発用ツールキット","author":"加藤 淳 and 坂本 大介 and 稲見 昌彦 and 五十嵐 健夫","year":"2011","month":"apr","journal":"情報処理学会論文誌","publisher":"Information Processing Society of Japan (IPSJ)","volume":"52","number":"4","pages":"1425--1437","issn":"03875806","url":"http://ci.nii.ac.jp/naid/110008507978/","language":"japanese","project":"phybots"}}]